{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5720713",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center; font-family:Georgia; font-weight:bold; \">Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636d64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b938b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e485d5",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center; font-family:Georgia; font-weight:bold; \">Constants and Global Variables</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af40173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv('Collected Datasets/text.csv')\n",
    "\n",
    "EMOTIONS = ['happiness', 'neutral', 'sadness', 'anger', 'fear', ]\n",
    "MAPPER = {emotion: [] for emotion in EMOTIONS}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.array(EMOTIONS)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "STOP_WORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9889ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Emotional Lexicons'''\n",
    "wordMap = pd.read_csv('wordMap.csv')\n",
    "for emotion in wordMap.columns.to_list():    \n",
    "    if emotion.lower() in EMOTIONS: MAPPER[emotion.lower()] = wordMap[emotion].to_list()\n",
    "    if emotion in ['Calm', 'Boredom']: MAPPER['neutral'] += wordMap[emotion].to_list()\n",
    "    if emotion in ['Excitement', 'Pride']: MAPPER['happiness'] += wordMap[emotion].to_list()\n",
    "    if emotion in ['Disgust', 'Frustration', 'Contempt']: MAPPER['anger'] += wordMap[emotion].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b268c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 195 entries, 0 to 262\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Contraction  195 non-null    object\n",
      " 1   Meaning      195 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.6+ KB\n"
     ]
    }
   ],
   "source": [
    "'''Contractions'''\n",
    "with open(\"Common English Contractions/contractions.json\" , 'r') as file:\n",
    "    contractions = json.load(file)\n",
    "    \n",
    "contractions = pd.DataFrame(list(contractions.items()), columns=[\"Contraction\", \"Meaning\"])\n",
    "contractions = pd.concat([contractions, pd.read_csv(\"Common English Contractions/contractions.csv\")], ignore_index=True)\n",
    "contractions.drop_duplicates(inplace=True)\n",
    "contractions[\"Contraction\"] = contractions[\"Contraction\"].str.lower()\n",
    "contractions[\"Meaning\"] = contractions[\"Meaning\"].str.lower()\n",
    "contractions.info()\n",
    "contractions = contractions.set_index(\"Contraction\").to_dict()[\"Meaning\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1660d7",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center; font-family:Georgia; font-weight:bold; \">Cleaning and Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56be3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(data, f=\"train\"):\n",
    "    if f == \"train\":\n",
    "        data = scaler.fit_transform(data)\n",
    "    else:\n",
    "        data = scaler.transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c09fe048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data, f=\"train\"):\n",
    "    if f == \"train\":\n",
    "        data = encoder.fit_transform(data)\n",
    "    else:\n",
    "        data = encoder.transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd03783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(data):\n",
    "    count = 0\n",
    "    for contraction, meaning in contractions.items():\n",
    "        count += data['Text'].apply(lambda line: len(re.findall(rf'\\b{contraction}\\b', line))).sum()\n",
    "        data['Text'] = data['Text'].apply(\n",
    "            lambda line: re.sub(rf'\\b{contraction}\\b', meaning, line)\n",
    "            )\n",
    "        \n",
    "    print(\"Number of contractions removed:\", count)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe849037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNER(data):\n",
    "    data['Entities'] = data['Text'].apply(\n",
    "    lambda text: [(ent.text, ent.label_) for ent in nlp(text).ents]\n",
    "    )\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexiconScore(data):\n",
    "    for emotion, keywords in MAPPER.items():\n",
    "        scores = []\n",
    "        for text in data['Text']:\n",
    "            words = text.lower().split()\n",
    "            counter = Counter(words)\n",
    "            totalWords = len(words)\n",
    "            score = sum(counter[word] for word in keywords)\n",
    "            normalizedScore = score / totalWords if totalWords > 0 else 0.0\n",
    "            scores.append(normalizedScore)\n",
    "        data[f\"{emotion}Score\"] = scores\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf979e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopWordRemoval(data):\n",
    "    data[\"Text\"] = data[\"Text\"].apply(\n",
    "        lambda removeStopWords: [word for word in removeStopWords if word not in STOP_WORDS]\n",
    "        )\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dea787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "239ad138-49b5-4a35-aef0-4de2f6a0feb8",
       "rows": [
        [
         "0",
         "i expect and i feel content with that",
         "happiness"
        ],
        [
         "1",
         "i just couldnt help feeling a little bit bitter towards his great big happy grin",
         "happiness"
        ],
        [
         "2",
         "i dunno how it feels to be completely happy the real world has taught me about struggle but what i m going thru is nothing close to struggle",
         "happiness"
        ],
        [
         "3",
         "i walk in the door to my house i feel happy",
         "happiness"
        ],
        [
         "4",
         "i feel satisfied and happy with my choices today",
         "happiness"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i expect and i feel content with that</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i just couldnt help feeling a little bit bitte...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dunno how it feels to be completely happy th...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i walk in the door to my house i feel happy</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel satisfied and happy with my choices today</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Emotion\n",
       "0              i expect and i feel content with that  happiness\n",
       "1  i just couldnt help feeling a little bit bitte...  happiness\n",
       "2  i dunno how it feels to be completely happy th...  happiness\n",
       "3        i walk in the door to my house i feel happy  happiness\n",
       "4   i feel satisfied and happy with my choices today  happiness"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(data):\n",
    "    data[\"Text\"] = data[\"Text\"].apply(\n",
    "        lambda text: word_tokenize(text)\n",
    "        )\n",
    "    \n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
